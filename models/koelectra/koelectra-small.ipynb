{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263fd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import ElectraTokenizer\n",
    "from transformers import TFElectraModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42a189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      class                                       conversation\n",
       "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "train_data_path =\"train.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830136fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b05022a6ff347d285ae2cbb6fe6974c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/257k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f9933e4b2444368dae0562edae7e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d11f5e160644ea5adf65def65a9076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/458 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토크나이저\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-small-v3-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3667650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "START_TOKEN = '[CLS]'\n",
    "END_TOKEN = '[SEP]'\n",
    "\n",
    "def tokenize(conversations):  \n",
    "    res = []\n",
    "    for conversation in conversations:\n",
    "        #tokens = [tokenizer.bos_token] + tokenizer.tokenize(conversation) + [tokenizer.eos_token]\n",
    "        tokens = [START_TOKEN] + tokenizer.tokenize(conversation) + [END_TOKEN]\n",
    "        res.append(tokenizer.convert_tokens_to_ids(tokens))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb73eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['지금', '너', '스스로', '##를', '죽여', '##달라', '##고', '애원', '##하', '##는', '것', '##인', '##가', '?', '아닙니다', '.', '죄송', '##합니다', '.', '죽', '##을', '거', '##면', '혼자', '죽', '##지', '우리', '##까', '##지', '사건', '##에', '휘말리', '##게', '해', '?', '진짜', '죽여', '##버리', '##고', '싶', '##게', '.', '정말', '잘못', '##했', '##습', '##니다', '.', '너', '##가', '선택', '##해', '.', '너', '##가', '죽', '##을', '##래', '네', '가족', '##을', '죽여', '##줄', '##까', '.', '죄송', '##합니다', '.', '정말', '잘못', '##했', '##습', '##니다', '.', '너', '##에', '##게', '##는', '선택', '##권', '##이', '없', '##어', '.', '선택', '못', '##한다', '##면', '너', '##와', '네', '가족', '##까', '##지', '모조리', '죽여', '##버릴', '##거', '##야', '.', '선택', '못하', '##겠', '##습', '##니다', '.', '한', '##번', '##만', '도와', '##주', '##세요', '.', '그냥', '다', '죽여', '##버려', '##야', '##겠', '##군', '.', '이의', '없', '##지', '?', '제발', '도와', '##주', '##세요', '.']\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 테스트\n",
    "print(tokenizer.tokenize(train_data['conversation'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1dfa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 토큰화\n",
    "tokenized = tokenize(train_data['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a471dc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6292, 2267, 6926, 4110, 13647, 28485, 4219, 26201, 4279, 4034, 2048, 4139, 4070, 35, 9312, 18, 11946, 17788, 18, 3324, 4292, 2041, 4181, 7422, 3324, 4200, 6233, 4149, 4200, 6388, 4073, 28110, 4325, 3764, 35, 7082, 13647, 13864, 4219, 3018, 4325, 18, 6595, 6997, 4398, 4576, 6216, 18, 2267, 4070, 6634, 4151, 18, 2267, 4070, 3324, 4292, 4395, 2279, 6507, 4292, 13647, 4612, 4149, 18, 11946, 17788, 18, 6595, 6997, 4398, 4576, 6216, 18, 2267, 4073, 4325, 4034, 6634, 4046, 4007, 3123, 4025, 18, 6634, 2684, 7796, 4181, 2267, 4192, 2279, 6507, 4149, 4200, 16285, 13647, 25748, 4216, 4474, 18, 6634, 31397, 5012, 4576, 6216, 18, 3757, 4467, 4172, 7733, 4076, 8553, 18, 6848, 2348, 13647, 15746, 4474, 5012, 4397, 18, 7818, 3123, 4200, 35, 11777, 7733, 4076, 8553, 18, 3] 3950\n"
     ]
    }
   ],
   "source": [
    "print(tokenized[0], len(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "886a2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 구하기\n",
    "def max_token_length(tokenized):\n",
    "    max_length = 0\n",
    "    #len_tokens = []\n",
    "    for t in tokenized:\n",
    "        if (len(t) > max_length):\n",
    "            max_length = len(t)\n",
    "        #len_tokens.append(len(t))\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac26e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max_token_length(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cae0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 레이블을 숫자 레이블로 변환\n",
    "def labelize(text):\n",
    "    res = []\n",
    "    for element in text:\n",
    "        if element == \"협박 대화\":\n",
    "            res.append(0)\n",
    "        elif element == \"갈취 대화\":\n",
    "            res.append(1)\n",
    "        elif element == \"직장 내 괴롭힘 대화\":\n",
    "            res.append(2)\n",
    "        elif element == \"기타 괴롭힘 대화\":\n",
    "            res.append(3)\n",
    "        else:\n",
    "            print(element)\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002749e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "def padding(data, pad_len):\n",
    "    res = []\n",
    "    for tokens in data:\n",
    "        if len(tokens) <= pad_len:\n",
    "            res.append(tokens)\n",
    "\n",
    "    res = tf.keras.preprocessing.sequence.pad_sequences(res, maxlen=pad_len, padding='post')\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98dcb5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = padding(tokenized, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db4c3776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2  6292  2267  6926  4110 13647 28485  4219 26201  4279  4034  2048\n",
      "  4139  4070    35  9312    18 11946 17788    18  3324  4292  2041  4181\n",
      "  7422  3324  4200  6233  4149  4200  6388  4073 28110  4325  3764    35\n",
      "  7082 13647 13864  4219  3018  4325    18  6595  6997  4398  4576  6216\n",
      "    18  2267  4070  6634  4151    18  2267  4070  3324  4292  4395  2279\n",
      "  6507  4292 13647  4612  4149    18 11946 17788    18  6595  6997  4398\n",
      "  4576  6216    18  2267  4073  4325  4034  6634  4046  4007  3123  4025\n",
      "    18  6634  2684  7796  4181  2267  4192  2279  6507  4149  4200 16285\n",
      " 13647 25748  4216  4474    18  6634 31397  5012  4576  6216    18  3757\n",
      "  4467  4172  7733  4076  8553    18  6848  2348 13647 15746  4474  5012\n",
      "  4397    18  7818  3123  4200    35 11777  7733  4076  8553    18     3\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0] (3950, 469)\n"
     ]
    }
   ],
   "source": [
    "print(tokenized[0], tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc2a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labelize(train_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "219caa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3950\n"
     ]
    }
   ],
   "source": [
    "print(label[0], len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ec61982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9650654d0abe4793971f12f5d5715f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/54.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['electra.embeddings.position_ids', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_trained_model = TFElectraModel.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00456764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 469)]             0         \n",
      "_________________________________________________________________\n",
      "tf_electra_model (TFElectraM TFBaseModelOutput(last_hi 14056192  \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,057,477\n",
      "Trainable params: 14,057,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "NUM_CLASS = 5\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32)\n",
    "hidden_1 = pre_trained_model([inputs])\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASS, activation=\"softmax\")(hidden_1['last_hidden_state'][:,-1])\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f74901ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "124/124 [==============================] - 105s 718ms/step - loss: 1.4416 - accuracy: 0.2441\n",
      "Epoch 2/10\n",
      "124/124 [==============================] - 92s 741ms/step - loss: 1.3996 - accuracy: 0.2456\n",
      "Epoch 3/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3981 - accuracy: 0.2554\n",
      "Epoch 4/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.4006 - accuracy: 0.2549\n",
      "Epoch 5/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3972 - accuracy: 0.2603\n",
      "Epoch 6/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3928 - accuracy: 0.2559\n",
      "Epoch 7/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3929 - accuracy: 0.2623\n",
      "Epoch 8/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3897 - accuracy: 0.2603\n",
      "Epoch 9/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3894 - accuracy: 0.2575\n",
      "Epoch 10/10\n",
      "124/124 [==============================] - 92s 742ms/step - loss: 1.3879 - accuracy: 0.2734\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "train_x = np.array(tokenized)\n",
    "train_y = np.array(label)\n",
    "\n",
    "history = model.fit(x=train_x, y=train_y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84edbfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 469)]             0         \n",
      "_________________________________________________________________\n",
      "tf_electra_model (TFElectraM TFBaseModelOutput(last_hi 14056192  \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,057,477\n",
      "Trainable params: 14,057,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 2 - Dropout 추가\n",
    "inputs = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32)\n",
    "hidden_1 = pre_trained_model([inputs])\n",
    "hidden_1 = hidden_1['last_hidden_state'][:,-1]\n",
    "hidden_2 = tf.keras.layers.Dropout(0.2)(hidden_1)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASS, activation=\"softmax\")(hidden_2)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07f9b532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "124/124 [==============================] - 106s 741ms/step - loss: 1.4141 - accuracy: 0.2701\n",
      "Epoch 2/10\n",
      " 28/124 [=====>........................] - ETA: 1:11 - loss: 1.4082 - accuracy: 0.2533"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/4198343514.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x=train_x, y=train_y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "463a1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 469)]             0         \n",
      "_________________________________________________________________\n",
      "tf_electra_model (TFElectraM TFBaseModelOutput(last_hi 14056192  \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_3 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 14,072,900\n",
      "Trainable params: 14,072,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 3 - Dense 층 추가\n",
    "inputs = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32)\n",
    "hidden_1 = pre_trained_model([inputs])\n",
    "hidden_1 = hidden_1['last_hidden_state'][:,-1]\n",
    "hidden_2 = tf.keras.layers.Dense(64, activation=\"relu\")(hidden_1)\n",
    "hidden_3 = tf.keras.layers.Dropout(0.5)(hidden_2)\n",
    "outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(hidden_3)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "579e1435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "124/124 [==============================] - 107s 742ms/step - loss: 1.3937 - accuracy: 0.2709\n",
      "Epoch 2/5\n",
      "124/124 [==============================] - 91s 735ms/step - loss: 1.3855 - accuracy: 0.2777\n",
      "Epoch 3/5\n",
      "124/124 [==============================] - 89s 717ms/step - loss: 1.3850 - accuracy: 0.2734\n",
      "Epoch 4/5\n",
      "124/124 [==============================] - 89s 719ms/step - loss: 1.3852 - accuracy: 0.2716\n",
      "Epoch 5/5\n",
      "124/124 [==============================] - 89s 715ms/step - loss: 1.3846 - accuracy: 0.2727\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x=train_x, y=train_y, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9667c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
