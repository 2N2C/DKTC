{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0218-gpt2.ipynb        data\t       submission_integers.csv\r\n",
      "checkpoint.weights.h5  submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.11.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFGPT2Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      class                                       conversation\n",
       "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path =\"~/aiffel/dktc/data/train.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 3950\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "3945    False\n",
       "3946    False\n",
       "3947    False\n",
       "3948    False\n",
       "3949    False\n",
       "Name: conversation, Length: 3950, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['conversation'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>병신이 아이스크림 먹게 돼 있냐?\\n난 먹으면 안 돼? 그만 좀 해.\\n당연히 안 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>523</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>과장님. 저 이번에 휴가 좀 갔다와도 되겠습니까.?\\n휴가? 왜??\\n좀 쉬다가 오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>789</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 얘 이 쪽 손가락 세 개밖에 없다\\n엥 손가락이 세개밖에 없을 수가 있어?\\n봐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>824</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>이야 내동생 여자친구한테 편지쓰네?\\n 아 형 돌려줘.\\n 어디보자. 사랑하는 여친...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>지현씨 나 소개팅 좀 시켜줘봐\\n네? 저 주변에 아는 사람이 없어서요\\n아 상사라 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3797</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 이번 방학 때 쌍꺼풀 수술 하고왔지?\\n아닌데?\\n아니긴 뭐가 아니야. 눈이 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>3798</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>안녕하세요 지금 먹방 촬영중인데 촬영가능할까요?\\n안돼요\\n한번만 안될까요?\\n안돼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>3855</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>그 소문 진짜야? 너가 다른 애들 뒷담화하고 다녔다며?\\n응? 나 그런 적 없는데?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>3874</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 니 왤캐 못생겼냐?\\n뭐라그랬냐?\\n으 나 보고 말하지마 니 얼굴보면 토나올거 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>3928</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>새파랗게 젊은게 어디 여길 앉아있어\\n저 임산부에요\\n사지 멀쩡한게! 임신이 벼슬이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx        class                                       conversation\n",
       "392    392    기타 괴롭힘 대화  병신이 아이스크림 먹게 돼 있냐?\\n난 먹으면 안 돼? 그만 좀 해.\\n당연히 안 ...\n",
       "523    523  직장 내 괴롭힘 대화  과장님. 저 이번에 휴가 좀 갔다와도 되겠습니까.?\\n휴가? 왜??\\n좀 쉬다가 오...\n",
       "789    789    기타 괴롭힘 대화  야 얘 이 쪽 손가락 세 개밖에 없다\\n엥 손가락이 세개밖에 없을 수가 있어?\\n봐...\n",
       "824    824    기타 괴롭힘 대화  이야 내동생 여자친구한테 편지쓰네?\\n 아 형 돌려줘.\\n 어디보자. 사랑하는 여친...\n",
       "869    869  직장 내 괴롭힘 대화  지현씨 나 소개팅 좀 시켜줘봐\\n네? 저 주변에 아는 사람이 없어서요\\n아 상사라 ...\n",
       "...    ...          ...                                                ...\n",
       "3797  3797    기타 괴롭힘 대화  너 이번 방학 때 쌍꺼풀 수술 하고왔지?\\n아닌데?\\n아니긴 뭐가 아니야. 눈이 이...\n",
       "3798  3798    기타 괴롭힘 대화  안녕하세요 지금 먹방 촬영중인데 촬영가능할까요?\\n안돼요\\n한번만 안될까요?\\n안돼...\n",
       "3855  3855    기타 괴롭힘 대화  그 소문 진짜야? 너가 다른 애들 뒷담화하고 다녔다며?\\n응? 나 그런 적 없는데?...\n",
       "3874  3874    기타 괴롭힘 대화  야 니 왤캐 못생겼냐?\\n뭐라그랬냐?\\n으 나 보고 말하지마 니 얼굴보면 토나올거 ...\n",
       "3928  3928    기타 괴롭힘 대화  새파랗게 젊은게 어디 여길 앉아있어\\n저 임산부에요\\n사지 멀쩡한게! 임신이 벼슬이...\n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated = train_data[train_data['conversation'].duplicated()]\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 리뷰 수 : 3846\n"
     ]
    }
   ],
   "source": [
    "# document 열에서 중복인 내용이 있다면 중복 제거\n",
    "train_data.drop_duplicates(subset=['conversation'], inplace=True)\n",
    "# Null 값이 존재하는 행 제거\n",
    "train_data = train_data.dropna(how='any')\n",
    "print('훈련 데이터의 리뷰 수 :',len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'협박 대화' : '00', '갈취 대화' : '01', '직장 내 괴롭힘 대화' :'02', '기타 괴롭힘 대화' : '03', '일반 대화' : '04'}\n",
    "train_data['label'] = train_data['class'].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타 괴롭힘 대화      1011\n",
       "갈취 대화           973\n",
       "직장 내 괴롭힘 대화     970\n",
       "협박 대화           892\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "03    1011\n",
       "01     973\n",
       "02     970\n",
       "00     892\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4130f4052c4a89b01710dd94a10ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0524525f219a44ab93837b1f3fe293ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', pad_token='<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['length'] = train_data['conversation'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['length'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['length'][1213]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네 아버님 안녕하십니까. 저는 따님의 남편이 될 길동 입니다.\\n어. 어서 오시게. 진짜 훤칠하네 우리 딸이 한눈에 반할만 해. 혹시 가족은 어떻게 되나?\\n저는 아버지 어머니 여동생 둘 이렇게 두고 있어요.\\n내가 보기와 다르게 대학교 공과대학 출신이야. 뭐 학벌 그렇게 중요하게 생각하지는 않는데. 부모님 학력은 어떻게 되나.?\\n저희 부모님은 아버지는 고졸이시고 어머니는 대학교 나오셨습니다.\\n고졸에 대학교. 대학교는 들어본 적 도 없는 대학교인데. 원래 학력이 낮은 집안이 재정도 떨어지지만 화목하지가 않아. 맨날 지들 서로가 잘났다고 싸워서 솔직히 내가 보기에는 다 머리 빈 애들 같은데 뭐 도토리 키재기에 길기리 노는거지. 그래서 그런데. 내가 당신을 믿어도 되나.? 부모님 두 분 학력이 그러시면 자네도 만만치않게 낮을거 같은데\\n아. 저도 똑같이 고졸입니다. 상업고를 졸업하고 바로 취업을 해서.\\n이봐이봐 이래서 부모의 학력이 중요해. 혹시 내딸과 결혼하면 애 낳아서 그 애도 고졸이 될지 어떻게알아? 내 딸 학력이 너무 아까운데\\n제가 꼭 대학교 보내겠습니다. 공부 열심히 배우게 해서 키울 자신 있습니다.\\n내가 고졸 사람 말을 어떻게 믿어. 혹시 알아? 폭력적인 성향이 있을수도 있잖아. 왜 도시별 범죄비율보면 빈곤한 도시가 더 범죄 많이 일어나잖아. 네 집이 어땠을지는 모르겠지만 그렇게 화목하지 않았을거라는것은 내가 장담해.\\n아닙니다 아버님. 저희 가족 완전 화목해요! 부모님 두 분 다 서글서글 하시고 있는 자리에서 최선다하고 계시고\\n자네 말을 믿기에는 아직 시간이 부족해. 우리 딸이 또 시집 살이 하는데 힘들수도 있고 우리딸 시집은 그래도 가족끼리 대화 많이 하고 서로 잘 배려해주는 곳으로 보내고 싶은데 왜 이런 집안인 애를 좋아하나 모르겠네.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['conversation'][1213]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9873, 9857, 7177, 25906, 8702, 7895, 23775, 389, 9265, 7162, 9106, 19495, 25533, 10341, 9367, 7244, 9241, 9361, 8006, 389, 9105, 7788, 9114, 7888, 6866, 389, 23971, 739, 8781, 8423, 8702, 7098, 9351, 28062, 20976, 9138, 8705, 7489, 9098, 389, 10039, 7888, 33624, 11649, 9069, 7055, 10604, 37767, 12683, 10375, 39616, 9710, 10917, 10447, 16444, 22507, 9049, 10234, 16835, 16217, 30636, 10454, 22882, 389, 46651, 9245, 7625, 14927, 20680, 9658, 14752, 9111, 9668, 389, 11676, 7177, 9245, 11859, 11649, 9069, 7055, 389, 10604, 8185, 8806, 11676, 32937, 11283, 30052, 8146, 34677, 12231, 16217, 12252, 7816, 10010, 6889, 8216, 8022, 16217, 389, 16217, 7162, 9359, 7655, 9211, 9095, 9712, 16217, 11848, 389, 10353, 49390, 11259, 39942, 11639, 7235, 11615, 31244, 9192, 7541, 9328, 6824, 11492, 389, 12829, 7060, 9027, 7285, 9919, 6824, 9443, 7065, 9217, 10406, 19647, 12980, 8264, 8811, 17582, 9049, 11351, 9054, 11980, 9818, 9831, 7285, 9239, 7220, 46651, 9095, 25145, 10252, 8170, 9399, 9367, 6958, 7478, 41754, 6853, 8263, 389, 11403, 10910, 389, 17582, 9162, 10705, 10653, 12821, 9069, 7055, 389, 406, 11676, 7177, 9174, 9129, 49390, 9198, 7888, 7532, 9042, 7098, 7235, 9103, 7489, 8420, 7969, 6866, 50856, 6853, 9239, 7220, 375, 7965, 389, 9265, 7235, 27179, 30052, 21154, 11249, 11276, 20319, 10021, 9499, 11938, 12341, 9585, 8146, 7661, 8146, 7661, 11499, 7788, 22484, 49390, 9861, 8711, 389, 10039, 7888, 9094, 7306, 6903, 10715, 9511, 9831, 11284, 11117, 9022, 39203, 30052, 8146, 10341, 8263, 11649, 7970, 7965, 406, 9094, 10265, 49390, 12371, 9050, 6969, 9493, 375, 10072, 12642, 16217, 11219, 6872, 16691, 11018, 22805, 11439, 6866, 12341, 10252, 8095, 9415, 10590, 22507, 30052, 9179, 11271, 11649, 37490, 389, 10039, 7888, 11560, 406, 22934, 9090, 45990, 9846, 14520, 9019, 8162, 7965, 389, 10401, 9647, 7644, 13061, 38906, 18381, 20234, 8704, 19347, 9267, 13061, 9564, 10124, 8162, 7965, 389, 9873, 27764, 9105, 7317, 8137, 9272, 42138, 9176, 14927, 9192, 7541, 9328, 24935, 6853, 9316, 41481, 17582, 9110, 7191, 8711, 9585, 7965, 7178, 7172, 7182, 9857, 7177, 389, 9265, 8806, 10464, 10253, 9192, 7541, 8711, 8084, 376, 11676, 7177, 9174, 9129, 9054, 9071, 6951, 7788, 6951, 9078, 34677, 9080, 20241, 9212, 7791, 7182, 9038, 32690, 6889, 375, 8159, 7098, 11271, 10653, 11351, 11059, 14553, 10667, 8711, 389, 9351, 28062, 9108, 12296, 26291, 14696, 20164, 14520, 10038, 9351, 7306, 12296, 8135, 31416, 10464, 18264, 17305, 9564, 9676, 9919, 9443, 22329, 18566, 14247, 39005, 22386, 7220, 10401, 10165, 13914, 8148, 9831, 7470, 12011, 11698, 42138, 25830]\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "test = tokenizer.encode(train_data['conversation'][1213])\n",
    "print(test)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    input_ids, data_labels = [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "\n",
    "        bos_token = [tokenizer.bos_token]\n",
    "        eos_token = [tokenizer.eos_token]\n",
    "        tokens = bos_token + tokenizer.tokenize(example) + eos_token\n",
    "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        input_ids.append(input_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return input_ids, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq len : 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3846/3846 [00:01<00:00, 1975.08it/s]\n"
     ]
    }
   ],
   "source": [
    "max_idx = train_data['length'].idxmax()\n",
    "temp = tokenizer.encode(train_data['conversation'][max_idx])\n",
    "max_seq_len = len(temp)\n",
    "print(f'max seq len : {max_seq_len}')\n",
    "\n",
    "train_X, train_y = convert_examples_to_features(train_data['conversation'], train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    1  9782 10099 24775 30707 24833  9831  8104  9033 12657 19635 35691\n",
      " 12521 11482  7832 11387 14909  9122  7532 16288 40401  9351  9168 20683\n",
      " 31424 12906  9098   406 23971 30707 40809 13358  6866  9585 29205 12222\n",
      "  8718 10010 10099  6824 11814  8711   389 10099  6824 14909  7383  9873\n",
      " 24173 30707  8239 21598 11482  7832 37194 29205 12222  8718 10010 10099\n",
      " 12333 11814 11067 10811   389 11814  9350 16337 10099  8066  9873 10464\n",
      "  9168  9079 28936 30707  7621  7481  6853  7991  9585 11814  9350 26616\n",
      " 16691 15354  7489 35498 41547 25689  9054 30707  7621 27436  6872  6921\n",
      "   389 15577 33473 10604  9037  7601 35498  7801 25856     1     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3]\n",
      "각 인코딩의 길이 : 404\n",
      "정수 인코딩 복원 : </s> 지금 너 스스로를 죽여달라고 애원하는 것인가?\n",
      " 아닙니다. 죄송합니다.\n",
      " 죽을 거면 혼자 죽지 우리까지 사건에 휘말리게 해? 진짜 죽여버리고 싶게.\n",
      " 정말 잘못했습니다.\n",
      " 너가 선택해. 너가 죽을래 네 가족을 죽여줄까.\n",
      " 죄송합니다. 정말 잘못했습니다.\n",
      " 너에게는 선택권이 없어. 선택 못한다면 너와 네 가족까지 모조리 죽여버릴거야.\n",
      " 선택 못하겠습니다. 한번만 도와주세요.\n",
      " 그냥 다 죽여버려야겠군. 이의 없지?\n",
      " 제발 도와주세요.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "레이블 : 0\n"
     ]
    }
   ],
   "source": [
    "input_id = train_X[0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd137d44b8948aab545e82849cd2322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/490M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2Model.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n",
    "outputs = model([input_ids_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2Model\n",
    "\n",
    "class TFGPT2ForSequenceClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TFGPT2ForSequenceClassification, self).__init__()\n",
    "        \n",
    "        self.gpt = TFGPT2Model.from_pretrained(model_name, from_pt=True)\n",
    "        # 클래스 개수 저장\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "        self.classifier = tf.keras.layers.Dense(\n",
    "            # 출력 뉴런 수 = 클래스 개수\n",
    "            num_labels,\n",
    "            kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "            # 다중 클래스 분류이므로 softmax 사용\n",
    "            activation='softmax',\n",
    "            name='classifier')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.gpt(input_ids=inputs)\n",
    "        # 마지막 토큰 가져오기\n",
    "        cls_token = outputs[0][:, -1]\n",
    "        cls_token = self.dropout(cls_token)\n",
    "        prediction = self.classifier(cls_token)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'MINICONDA_VERSION': '4.9.2',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8888_TCP_PROTO': 'tcp',\n",
       "        'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-4',\n",
       "        'NV_LIBCUBLAS_VERSION': '11.6.1.51-1',\n",
       "        'KUBERNETES_SERVICE_PORT': '443',\n",
       "        'KUBERNETES_PORT': 'tcp://10.88.0.1:443',\n",
       "        'LANGUAGE': 'en_US:en',\n",
       "        'HOSTNAME': 'wo7srmohwd5ovihcsypxsosu2-56c9d4dc8c-vvhnl',\n",
       "        'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\n",
       "        'NV_LIBNCCL_PACKAGE_VERSION': '2.11.4-1',\n",
       "        'HOME': '/aiffel',\n",
       "        'NV_CUDNN_PACKAGE_NAME': 'libcudnn8',\n",
       "        'CONDA_VERSION': '4.9.2',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8887_TCP': 'tcp://10.88.11.64:8887',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8888_TCP': 'tcp://10.88.11.64:8888',\n",
       "        'TF_CPP_MIN_LOG_LEVEL': '3',\n",
       "        'NV_LIBNPP_PACKAGE': 'libnpp-11-4=11.4.0.110-1',\n",
       "        'CUDA_VERSION': '11.4.2',\n",
       "        'NV_CUDNN_PACKAGE': 'libcudnn8=8.2.4.15-1+cuda11.4',\n",
       "        'DEFAULT_JUPYTER_TOKEN': '',\n",
       "        'WORKSPACE_HOME': '/workspace',\n",
       "        'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-11-4',\n",
       "        'CONDA_ROOT': '/opt/conda',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_SERVICE_PORT_HTTP_TCP8887': '8887',\n",
       "        'NVIDIA_REQUIRE_CUDA': 'cuda>=11.4 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_SERVICE_PORT_HTTP_TCP8888': '8888',\n",
       "        'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility',\n",
       "        'NV_CUDA_LIB_VERSION': '11.4.2-1',\n",
       "        'NV_LIBCUSPARSE_VERSION': '11.6.0.120-1',\n",
       "        'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2',\n",
       "        'NV_CUDA_CUDART_VERSION': '11.4.108-1',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_SERVICE_HOST': '10.88.11.64',\n",
       "        'KUBERNETES_PORT_443_TCP_ADDR': '10.88.0.1',\n",
       "        'PATH': '/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
       "        'NVARCH': 'x86_64',\n",
       "        'NV_LIBCUBLAS_PACKAGE': 'libcublas-11-4=11.6.1.51-1',\n",
       "        'KUBERNETES_PORT_443_TCP_PORT': '443',\n",
       "        'NV_LIBNCCL_PACKAGE': 'libnccl2=2.11.4-1+cuda11.4',\n",
       "        'CONDA_PYTHON_DIR': '/opt/conda/lib/python3.9',\n",
       "        'KUBERNETES_PORT_443_TCP_PROTO': 'tcp',\n",
       "        'LANG': 'en_US.UTF-8',\n",
       "        'TF_FORCE_GPU_ALLOW_GROWTH': 'true',\n",
       "        'DEBIAN_FRONTEND': 'noninteractive',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_SERVICE_PORT': '8888',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT': 'tcp://10.88.11.64:8888',\n",
       "        'SHELL': '/bin/bash',\n",
       "        'PYTHON_VERSION': '3.9.7',\n",
       "        'nodePoolLabel': 'image.pull.ready=true',\n",
       "        'NV_NVTX_VERSION': '11.4.120-1',\n",
       "        'NV_LIBNPP_VERSION': '11.4.0.110-1',\n",
       "        'CONDA_DIR': '/opt/conda',\n",
       "        'KUBERNETES_PORT_443_TCP': 'tcp://10.88.0.1:443',\n",
       "        'KUBERNETES_SERVICE_PORT_HTTPS': '443',\n",
       "        'NV_CUDNN_VERSION': '8.2.4.15',\n",
       "        'LC_ALL': 'en_US.UTF-8',\n",
       "        'KUBERNETES_SERVICE_HOST': '10.88.0.1',\n",
       "        'PWD': '/aiffel',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8887_TCP_ADDR': '10.88.11.64',\n",
       "        'PYTHONPATH': '/aiffel/storage/package/',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8888_TCP_ADDR': '10.88.11.64',\n",
       "        'NVIDIA_VISIBLE_DEVICES': 'all',\n",
       "        'NCCL_VERSION': '2.11.4-1',\n",
       "        'USER_GID': '0',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8887_TCP_PORT': '8887',\n",
       "        'MINICONDA_MD5': '122c8c9beb51e124ab32a0fa6426c656',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8888_TCP_PORT': '8888',\n",
       "        'WO7SRMOHWD5OVIHCSYPXSOSU2_PORT_8887_TCP_PROTO': 'tcp',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'JPY_PARENT_PID': '7',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       "        'TF2_BEHAVIOR': '1'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Wed Feb 19 02:25:58 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.216.01             Driver Version: 535.216.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0              26W /  70W |   1463MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        32      C   /opt/conda/bin/python                         0MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy() if tf.config.list_physical_devices('GPU') else tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint_path = os.getenv('HOME')+'/aiffel/dktc/checkpoint.weights.h5'\n",
    "\n",
    "with strategy.scope():\n",
    "  model = TFGPT2ForSequenceClassification(model_name=\"skt/kogpt2-base-v2\", num_labels=5)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "  # from_logits=False (Softmax 출력)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "  es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "  mc = ModelCheckpoint(checkpoint_path, save_weights_only=True, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "385/385 [==============================] - 341s 837ms/step - loss: 0.9303 - accuracy: 0.6785 - val_loss: 0.5579 - val_accuracy: 0.8039\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55792, saving model to /aiffel/aiffel/dktc/checkpoint.weights.h5\n",
      "Epoch 2/10\n",
      "385/385 [==============================] - 326s 846ms/step - loss: 0.4286 - accuracy: 0.8479 - val_loss: 0.5479 - val_accuracy: 0.7896\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55792 to 0.54789, saving model to /aiffel/aiffel/dktc/checkpoint.weights.h5\n",
      "Epoch 3/10\n",
      "385/385 [==============================] - 326s 846ms/step - loss: 0.2896 - accuracy: 0.9025 - val_loss: 0.6449 - val_accuracy: 0.8234\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.54789\n",
      "Epoch 4/10\n",
      "385/385 [==============================] - 326s 846ms/step - loss: 0.2029 - accuracy: 0.9321 - val_loss: 0.8034 - val_accuracy: 0.7818\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.54789\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs=10, batch_size=8, callbacks=[es, mc], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003</th>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
       "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
       "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
       "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
       "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "test_json_path = os.getenv('HOME')+'/aiffel/dktc/data/test.json'\n",
    "\n",
    "# JSON 파일 불러오기\n",
    "with open(test_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 변환: key를 인덱스로 하고, 내부 \"text\" 값을 컬럼으로 변환\n",
    "test_data = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "def classify(sentence):\n",
    "  bos_token = [tokenizer.bos_token]\n",
    "  eos_token = [tokenizer.eos_token]\n",
    "\n",
    "  tokens = bos_token + tokenizer.tokenize(sentence) + eos_token\n",
    "  input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "  input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
    "  input_id = np.array([input_id])\n",
    "\n",
    "  scores = model.predict(input_id)[0]\n",
    "  # 가장 높은 확률을 가진 클래스 선택\n",
    "  predicted_class = np.argmax(scores)\n",
    "  confidence = np.max(scores) * 100\n",
    "\n",
    "  return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나보네 그럼 취소할까요 아가씨 내 여기단골이니 담에 갖다줄께 저도 알바생이라 외상안됩니다 아따 누가 떼먹는다고 그러나 갖다준다고 안됩니다 자꾸이럼 경찰불러요 아가씨 담배피는교 그건 왜 물으세요 그람 아가씨 담배 한대만 빌립시다 내 지금 지갑도 잃어버리고 기분이 그래서 그러니 여기요  아따 주는김에 한개더 주면 되겠네'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(test_data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003</th>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...       1\n",
       "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...       2\n",
       "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...       2\n",
       "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...       3\n",
       "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...       0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['target'] = test_data['text'].apply(classify)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  target\n",
       "0  t_000       1\n",
       "1  t_001       2\n",
       "2  t_002       2\n",
       "3  t_003       3\n",
       "4  t_004       0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = test_data[['target']].reset_index()\n",
    "output_df.rename(columns={'index': 'idx'}, inplace=True)\n",
    "\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getenv('HOME')+'/aiffel/dktc/submission.csv'\n",
    "output_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
