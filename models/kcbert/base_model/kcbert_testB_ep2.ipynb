{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f514b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b862123",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/advanced_general_conversation_test_B.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905fd8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>4520</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그 사람 또 늦게 왔어요.\\n진짜? 지난번에도 지각하더니.\\n아니, 무슨 일하는 태...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>4521</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>네 친구 또 돈 빌려 달라고 했어.\\n진짜? 지난번에도 안 갚았잖아.\\n아니, 무슨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>4522</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그 동료 또 실수했어요.\\n진짜? 이번엔 또 뭐야?\\n아니, 기본적인 것도 못 하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>4523</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>걔 또 허세 부리더라.\\n진짜? 저번에도 그러지 않았어?\\n아니, 대체 왜 저러는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>4524</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그 사람 또 자기합리화했어요.\\n진짜? 매번 그러더니.\\n아니, 실수를 인정하는 게...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4525 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx      class                                       conversation\n",
       "0        0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1        1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2        2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3        3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4        4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...\n",
       "...    ...        ...                                                ...\n",
       "4520  4520      일반 대화  그 사람 또 늦게 왔어요.\\n진짜? 지난번에도 지각하더니.\\n아니, 무슨 일하는 태...\n",
       "4521  4521      일반 대화  네 친구 또 돈 빌려 달라고 했어.\\n진짜? 지난번에도 안 갚았잖아.\\n아니, 무슨...\n",
       "4522  4522      일반 대화  그 동료 또 실수했어요.\\n진짜? 이번엔 또 뭐야?\\n아니, 기본적인 것도 못 하는...\n",
       "4523  4523      일반 대화  걔 또 허세 부리더라.\\n진짜? 저번에도 그러지 않았어?\\n아니, 대체 왜 저러는 ...\n",
       "4524  4524      일반 대화  그 사람 또 자기합리화했어요.\\n진짜? 매번 그러더니.\\n아니, 실수를 인정하는 게...\n",
       "\n",
       "[4525 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c11314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['협박 대화', '기타 괴롭힘 대화', '갈취 대화', '직장 내 괴롭힘 대화', '일반 대화'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b21a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'협박 대화' : 0, '갈취 대화' : 1, '직장 내 괴롭힘 대화' :2, '기타 괴롭힘 대화' : 3, '일반 대화' : 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64736472",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['int_class'] = train_data['class'].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d537e2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>int_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>4520</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그 사람 또 늦게 왔어요.\\n진짜? 지난번에도 지각하더니.\\n아니, 무슨 일하는 태...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>4521</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>네 친구 또 돈 빌려 달라고 했어.\\n진짜? 지난번에도 안 갚았잖아.\\n아니, 무슨...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>4522</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그 동료 또 실수했어요.\\n진짜? 이번엔 또 뭐야?\\n아니, 기본적인 것도 못 하는...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>4523</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>걔 또 허세 부리더라.\\n진짜? 저번에도 그러지 않았어?\\n아니, 대체 왜 저러는 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>4524</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그 사람 또 자기합리화했어요.\\n진짜? 매번 그러더니.\\n아니, 실수를 인정하는 게...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4525 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx      class                                       conversation  \\\n",
       "0        0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
       "1        1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
       "2        2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
       "3        3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
       "4        4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
       "...    ...        ...                                                ...   \n",
       "4520  4520      일반 대화  그 사람 또 늦게 왔어요.\\n진짜? 지난번에도 지각하더니.\\n아니, 무슨 일하는 태...   \n",
       "4521  4521      일반 대화  네 친구 또 돈 빌려 달라고 했어.\\n진짜? 지난번에도 안 갚았잖아.\\n아니, 무슨...   \n",
       "4522  4522      일반 대화  그 동료 또 실수했어요.\\n진짜? 이번엔 또 뭐야?\\n아니, 기본적인 것도 못 하는...   \n",
       "4523  4523      일반 대화  걔 또 허세 부리더라.\\n진짜? 저번에도 그러지 않았어?\\n아니, 대체 왜 저러는 ...   \n",
       "4524  4524      일반 대화  그 사람 또 자기합리화했어요.\\n진짜? 매번 그러더니.\\n아니, 실수를 인정하는 게...   \n",
       "\n",
       "      int_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             3  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "4520          4  \n",
       "4521          4  \n",
       "4522          4  \n",
       "4523          4  \n",
       "4524          4  \n",
       "\n",
       "[4525 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7718f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c24faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"monologg/koelectra-small-v2-distilled-korquad-384\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "#model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME, num_labels=5, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8393851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"beomi/kcbert-base\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFBertModel.from_pretrained(MODEL_NAME, num_labels=5, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbad783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장에서 가장 긴 토큰 개수: 386\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 토큰화 (문장별 토큰 개수 확인)\n",
    "tokenized_texts = [tokenizer.tokenize(text) for text in train_data['conversation']]\n",
    "\n",
    "# 각 문장의 토큰 개수 계산\n",
    "token_lengths = [len(tokens) for tokens in tokenized_texts]\n",
    "\n",
    "# 최대 토큰 개수 찾기\n",
    "max_token_length = max(token_lengths)\n",
    "\n",
    "print(f\"문장에서 가장 긴 토큰 개수: {max_token_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd57125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전 개수 확인\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f810e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "# 특수 토큰 확인\n",
    "print(tokenizer.cls_token)\n",
    "print(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70685faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 토큰 인텍스, 문장, 토큰 수 확인\n",
    "max_token_idx = token_lengths.index(max(token_lengths))  # 가장 긴 문장의 인덱스\n",
    "max_token_text = train_data['conversation'].iloc[max_token_idx]  # 해당 문장\n",
    "max_token_count = token_lengths[max_token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286c62ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이게 어떻게 된거야.? 엄마 수술은 어떻게 된거냐고\\n 엄마가 이제 괜찮다고 해서 딱 봐도 많이 좋아지셨잖아. 굳이 수술까진 할 필요 없어보여서.\\n 뭐? 그걸 왜 누나가 정해? 누나가 의사야? 병원가서 정밀검사 받아보고 해야지. 큰 병이면 어쩌려고 그래?\\n 아 늙어서 몸도 성하지 않는 사람 수술해서 뭐 어쩔건데????\\n 그럼 내가 준 수술비는 어쨌는데. 급하다며 급하다고 해서 내가 돈 다 빼서 줬잖아. 그거 어딨냐고 !!!!!!!!!\\n 그건 다른 급한 곳에 썼어.\\n 하. 급한 곳? 뭔데 어디다 썼는데.\\n 엄마 모시고 살면 돈 나가는 곳이 한 두 군데니? 이것 저것 급한 곳들 돈 썼지. 니가 말하면 알아?\\n 이건 뭐야? 못 보던건데. 누나 또 명품샀어?\\n 아 내놔!!!!!!!! 니가 뭘 알아. 아니야 이거 원래 있던거야.\\n 하. 니가 그러고도 인간이야? 그게 어떤돈인데!!!!!!!!!!!! 내가 밤낮으로 잠도 못자가면서 번 돈 !!!!!! 엄마 수술비하라고 다 빼서 준 걸 니가 가방을 쳐 사는데 써???????????\\n 아 시끄러워. 나 바빠 가야해.\\n 이성을 잃은 듯 너같은 년이 죽어야하는데. 너같은 년은 살 가치가 없다. 너가 죽어 너가 !!!!!!!!!!!\\n 왜.왜이래??! 미쳤어?\\n 이제 도저히 못참겠다. 몇 년 동안 이게 몇 번째야? 이 짓거리 못하도록 그냥 널 병신 만드는게 낫겠다. 팔 다리를 부러뜨려야 밖으로 안싸돌아 다니지? 발목을 아주 잘라버려야겠어. 주변에 흉기를 찾는다\\n 미.미쳤어 왜이렇게 흥분해?!?!?\\n 공구함에 있던 망치를 들며 너 내가 오늘 가만 안둬. 미친 건 너야. 팔다리를 없애버리겠어.\\n 꺄아아아'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b282d895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4421c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max_token_count + 2 # 문장 최대 토큰 길이\n",
    "NUM_LABELS = 5  # 분류할 클래스 개수\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3addf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 토큰화하는 함수\n",
    "def tokenize_texts(texts, labels):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),  # 리스트 형태로 변환\n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=MAX_LEN, \n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings[\"input_ids\"], encodings[\"attention_mask\"], tf.convert_to_tensor(labels, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "136f8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (8:2 비율로 train/val 나누기)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_data['conversation'], train_data['int_class'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2283d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 토큰화\n",
    "train_input_ids, train_attention_mask, train_labels = tokenize_texts(train_texts, train_labels)\n",
    "val_input_ids, val_attention_mask, val_labels = tokenize_texts(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af0c2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Dataset 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": train_input_ids, \"attention_mask\": train_attention_mask}, train_labels)\n",
    ").shuffle(len(train_texts)).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask}, val_labels)\n",
    ").batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bfae926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 (train_data['conversation'], train_data['int_class'] 사용)\n",
    "input_ids, attention_mask, label_tensor = tokenize_texts(train_data['conversation'], train_data['int_class'])\n",
    "\n",
    "# TensorFlow Dataset 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, label_tensor)\n",
    ")\n",
    "\n",
    "# 배치 및 섞기\n",
    "dataset = dataset.shuffle(len(train_data)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c881776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8926b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"f1_score\", **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred, axis=1)  # 가장 높은 확률값을 가진 클래스 선택\n",
    "        self.precision.update_state(y_true, y_pred)\n",
    "        self.recall.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))  # F1-score 계산\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd0233eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 388)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 388)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108918528   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            645         dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,017,605\n",
      "Trainable params: 109,017,605\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# BERT 모델에 입력\n",
    "bert_output = model(input_ids, attention_mask=attention_mask)[1]\n",
    "x = Dropout(0.3)(bert_output)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(NUM_LABELS, activation=\"softmax\")(x)  # 다중 클래스 분류\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b252f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 설정 (patience=2)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # 검증 데이터 손실 기준\n",
    "    patience=3,  # 3epoch 동안 개선되지 않으면 종료\n",
    "    restore_best_weights=True  # 가장 성능이 좋았던 가중치 복원\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d03244dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint 설정 (최적 모델 저장)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_kobert_testB_ep2.h5\",  # 저장할 모델 파일명\n",
    "    monitor=\"val_loss\",  # 검증 손실 기준으로 저장\n",
    "    save_best_only=True,  # 가장 성능 좋은 모델만 저장\n",
    "    save_weights_only=True,  # 가중치만 저장 (전체 모델 저장하려면 False)\n",
    "    verbose=1  # 저장될 때 로그 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc26758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.EarlyStopping object at 0x7ae2f1386b80>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_202/2791717052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 정상적으로 설정되었는지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "#print(early_stopping)  # 정상적으로 설정되었는지 확인\n",
    "#print(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98cb4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "277/453 [=================>............] - ETA: 2:00 - loss: 0.7024 - accuracy: 0.7459"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8038250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a95c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터 예측\n",
    "val_predictions = model.predict({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask})\n",
    "predicted_classes = np.argmax(val_predictions, axis=1)  # 확률값을 가장 높은 클래스 인덱스로 변환\n",
    "\n",
    "# F1-score 계산\n",
    "f1 = f1_score(val_labels, predicted_classes, average=\"weighted\")\n",
    "\n",
    "print(f\"검증 데이터 F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_test_texts(texts):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings[\"input_ids\"], encodings[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_mask = tokenize_test_texts(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65287b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 수행\n",
    "predictions = model.predict({\"input_ids\": test_input_ids, \"attention_mask\": test_attention_mask})\n",
    "\n",
    "# 확률값을 가장 높은 클래스 인덱스로 변환\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "test_data['target'] = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa304613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 예측된 결과 출력\n",
    "print(test_data[['text', 'target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f643c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 저장\n",
    "#test_data[['idx', 'target']].to_csv(\"submission_kobert_testB_ep2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d36c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['target'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91590bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 긴 텍스트 출력 제한 해제\n",
    "pd.options.display.max_colwidth = None  \n",
    "# 예측된 결과 출력\n",
    "display(test_data[test_data['target'] == 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
