{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec336a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68a292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_add_normal.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da662442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>4261</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야, 적 저격수 위치 확인했냐?\\n몰라, 어딘가 숨어있어.\\n아니 ㅅㅂ 이미 쏘고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>4262</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>팀원들 왜 이렇게 못 해??\\n몰라, 다들 손가락 부상당했나 봄.\\n아니 우리 팀 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>4263</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 적 네 뒤에! 뒤돌아봐!\\n뭐? 뭐? 어디?\\n아니 벌써 죽었냐? ㅋㅋㅋㅋㅋ\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>4264</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야야 거점 뺏긴다!!\\n아니 팀원들 뭐함? 다 자냐?\\n혼자 막기 개에바야, 도와줘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>4265</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 너 힐러 맞냐? 힐 좀 해줘!\\n아니 나도 피 없다고!!\\n그럼 뭐 어쩌라고? ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4266 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx      class                                       conversation\n",
       "0        0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1        1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2        2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3        3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4        4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...\n",
       "...    ...        ...                                                ...\n",
       "4261  4261      일반 대화  야, 적 저격수 위치 확인했냐?\\n몰라, 어딘가 숨어있어.\\n아니 ㅅㅂ 이미 쏘고 ...\n",
       "4262  4262      일반 대화  팀원들 왜 이렇게 못 해??\\n몰라, 다들 손가락 부상당했나 봄.\\n아니 우리 팀 ...\n",
       "4263  4263      일반 대화  야 적 네 뒤에! 뒤돌아봐!\\n뭐? 뭐? 어디?\\n아니 벌써 죽었냐? ㅋㅋㅋㅋㅋ\\n...\n",
       "4264  4264      일반 대화  야야 거점 뺏긴다!!\\n아니 팀원들 뭐함? 다 자냐?\\n혼자 막기 개에바야, 도와줘...\n",
       "4265  4265      일반 대화  야 너 힐러 맞냐? 힐 좀 해줘!\\n아니 나도 피 없다고!!\\n그럼 뭐 어쩌라고? ...\n",
       "\n",
       "[4266 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e0bc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['협박 대화', '기타 괴롭힘 대화', '갈취 대화', '직장 내 괴롭힘 대화', '일반 대화'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1607964",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'협박 대화' : 0, '갈취 대화' : 1, '직장 내 괴롭힘 대화' :2, '기타 괴롭힘 대화' : 3, '일반 대화' : 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7848ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['int_class'] = train_data['class'].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e64568f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>int_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>4261</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야, 적 저격수 위치 확인했냐?\\n몰라, 어딘가 숨어있어.\\n아니 ㅅㅂ 이미 쏘고 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>4262</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>팀원들 왜 이렇게 못 해??\\n몰라, 다들 손가락 부상당했나 봄.\\n아니 우리 팀 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>4263</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 적 네 뒤에! 뒤돌아봐!\\n뭐? 뭐? 어디?\\n아니 벌써 죽었냐? ㅋㅋㅋㅋㅋ\\n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>4264</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야야 거점 뺏긴다!!\\n아니 팀원들 뭐함? 다 자냐?\\n혼자 막기 개에바야, 도와줘...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>4265</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 너 힐러 맞냐? 힐 좀 해줘!\\n아니 나도 피 없다고!!\\n그럼 뭐 어쩌라고? ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4266 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx      class                                       conversation  \\\n",
       "0        0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
       "1        1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
       "2        2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
       "3        3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
       "4        4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
       "...    ...        ...                                                ...   \n",
       "4261  4261      일반 대화  야, 적 저격수 위치 확인했냐?\\n몰라, 어딘가 숨어있어.\\n아니 ㅅㅂ 이미 쏘고 ...   \n",
       "4262  4262      일반 대화  팀원들 왜 이렇게 못 해??\\n몰라, 다들 손가락 부상당했나 봄.\\n아니 우리 팀 ...   \n",
       "4263  4263      일반 대화  야 적 네 뒤에! 뒤돌아봐!\\n뭐? 뭐? 어디?\\n아니 벌써 죽었냐? ㅋㅋㅋㅋㅋ\\n...   \n",
       "4264  4264      일반 대화  야야 거점 뺏긴다!!\\n아니 팀원들 뭐함? 다 자냐?\\n혼자 막기 개에바야, 도와줘...   \n",
       "4265  4265      일반 대화  야 너 힐러 맞냐? 힐 좀 해줘!\\n아니 나도 피 없다고!!\\n그럼 뭐 어쩌라고? ...   \n",
       "\n",
       "      int_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             3  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "4261          4  \n",
       "4262          4  \n",
       "4263          4  \n",
       "4264          4  \n",
       "4265          4  \n",
       "\n",
       "[4266 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489182e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8b8509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"beomi/kcbert-base\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFBertModel.from_pretrained(MODEL_NAME, num_labels=5, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bacfd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장에서 가장 긴 토큰 개수: 386\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 토큰화 (문장별 토큰 개수 확인)\n",
    "tokenized_texts = [tokenizer.tokenize(text) for text in train_data['conversation']]\n",
    "\n",
    "# 각 문장의 토큰 개수 계산\n",
    "token_lengths = [len(tokens) for tokens in tokenized_texts]\n",
    "\n",
    "# 최대 토큰 개수 찾기\n",
    "max_token_length = max(token_lengths)\n",
    "\n",
    "print(f\"문장에서 가장 긴 토큰 개수: {max_token_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb0a5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전 개수 확인\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f212437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "# 특수 토큰 확인\n",
    "print(tokenizer.cls_token)\n",
    "print(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8300e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 토큰 인텍스, 문장, 토큰 수 확인\n",
    "max_token_idx = token_lengths.index(max(token_lengths))  # 가장 긴 문장의 인덱스\n",
    "max_token_text = train_data['conversation'].iloc[max_token_idx]  # 해당 문장\n",
    "max_token_count = token_lengths[max_token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e42354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이게 어떻게 된거야.? 엄마 수술은 어떻게 된거냐고\\n 엄마가 이제 괜찮다고 해서 딱 봐도 많이 좋아지셨잖아. 굳이 수술까진 할 필요 없어보여서.\\n 뭐? 그걸 왜 누나가 정해? 누나가 의사야? 병원가서 정밀검사 받아보고 해야지. 큰 병이면 어쩌려고 그래?\\n 아 늙어서 몸도 성하지 않는 사람 수술해서 뭐 어쩔건데????\\n 그럼 내가 준 수술비는 어쨌는데. 급하다며 급하다고 해서 내가 돈 다 빼서 줬잖아. 그거 어딨냐고 !!!!!!!!!\\n 그건 다른 급한 곳에 썼어.\\n 하. 급한 곳? 뭔데 어디다 썼는데.\\n 엄마 모시고 살면 돈 나가는 곳이 한 두 군데니? 이것 저것 급한 곳들 돈 썼지. 니가 말하면 알아?\\n 이건 뭐야? 못 보던건데. 누나 또 명품샀어?\\n 아 내놔!!!!!!!! 니가 뭘 알아. 아니야 이거 원래 있던거야.\\n 하. 니가 그러고도 인간이야? 그게 어떤돈인데!!!!!!!!!!!! 내가 밤낮으로 잠도 못자가면서 번 돈 !!!!!! 엄마 수술비하라고 다 빼서 준 걸 니가 가방을 쳐 사는데 써???????????\\n 아 시끄러워. 나 바빠 가야해.\\n 이성을 잃은 듯 너같은 년이 죽어야하는데. 너같은 년은 살 가치가 없다. 너가 죽어 너가 !!!!!!!!!!!\\n 왜.왜이래??! 미쳤어?\\n 이제 도저히 못참겠다. 몇 년 동안 이게 몇 번째야? 이 짓거리 못하도록 그냥 널 병신 만드는게 낫겠다. 팔 다리를 부러뜨려야 밖으로 안싸돌아 다니지? 발목을 아주 잘라버려야겠어. 주변에 흉기를 찾는다\\n 미.미쳤어 왜이렇게 흥분해?!?!?\\n 공구함에 있던 망치를 들며 너 내가 오늘 가만 안둬. 미친 건 너야. 팔다리를 없애버리겠어.\\n 꺄아아아'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5971e778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1647c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max_token_count + 2 # 문장 최대 토큰 길이\n",
    "NUM_LABELS = 5  # 분류할 클래스 개수\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c57fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 토큰화하는 함수\n",
    "def tokenize_texts(texts, labels):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),  # 리스트 형태로 변환\n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=MAX_LEN, \n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings[\"input_ids\"], encodings[\"attention_mask\"], tf.convert_to_tensor(labels, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ab5025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (8:2 비율로 train/val 나누기)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_data['conversation'], train_data['int_class'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "039840bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 토큰화\n",
    "train_input_ids, train_attention_mask, train_labels = tokenize_texts(train_texts, train_labels)\n",
    "val_input_ids, val_attention_mask, val_labels = tokenize_texts(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea410917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Dataset 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": train_input_ids, \"attention_mask\": train_attention_mask}, train_labels)\n",
    ").shuffle(len(train_texts)).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask}, val_labels)\n",
    ").batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c5796f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 (train_data['conversation'], train_data['int_class'] 사용)\n",
    "input_ids, attention_mask, label_tensor = tokenize_texts(train_data['conversation'], train_data['int_class'])\n",
    "\n",
    "# TensorFlow Dataset 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, label_tensor)\n",
    ")\n",
    "\n",
    "# 배치 및 섞기\n",
    "dataset = dataset.shuffle(len(train_data)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993508ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4266, 388), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fee6f09e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 388)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 388)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108918528   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            645         dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,017,605\n",
      "Trainable params: 109,017,605\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# BERT 모델에 입력\n",
    "bert_output = model(input_ids, attention_mask=attention_mask)[1]\n",
    "x = Dropout(0.1)(bert_output)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output = Dense(NUM_LABELS, activation=\"softmax\")(x)  # 다중 클래스 분류\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed066b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 설정 (patience=2)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # 검증 데이터 손실 기준\n",
    "    patience=2,  # 2 epoch 동안 개선되지 않으면 종료\n",
    "    restore_best_weights=True  # 가장 성능이 좋았던 가중치 복원\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a84650ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 342s 766ms/step - loss: 0.5107 - accuracy: 0.8200 - val_loss: 0.3533 - val_accuracy: 0.8888\n",
      "Epoch 2/5\n",
      "427/427 [==============================] - 324s 760ms/step - loss: 0.1630 - accuracy: 0.9513 - val_loss: 0.2909 - val_accuracy: 0.9075\n",
      "Epoch 3/5\n",
      "427/427 [==============================] - 325s 761ms/step - loss: 0.0713 - accuracy: 0.9763 - val_loss: 0.3238 - val_accuracy: 0.9145\n",
      "Epoch 4/5\n",
      "427/427 [==============================] - 325s 761ms/step - loss: 0.0457 - accuracy: 0.9842 - val_loss: 0.4231 - val_accuracy: 0.9110\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]  # 조기 종료 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f0b46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd41dfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 F1-score: 0.9072\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 예측\n",
    "val_predictions = model.predict({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask})\n",
    "predicted_classes = np.argmax(val_predictions, axis=1)  # 확률값을 가장 높은 클래스 인덱스로 변환\n",
    "\n",
    "# F1-score 계산\n",
    "f1 = f1_score(val_labels, predicted_classes, average=\"weighted\")\n",
    "\n",
    "print(f\"검증 데이터 F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6be69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_test_texts(texts):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings[\"input_ids\"], encodings[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1cfa216",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_mask = tokenize_test_texts(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f15b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 수행\n",
    "predictions = model.predict({\"input_ids\": test_input_ids, \"attention_mask\": test_attention_mask})\n",
    "\n",
    "# 확률값을 가장 높은 클래스 인덱스로 변환\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "test_data['predicted_class'] = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "553e521c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  predicted_class\n",
      "0    아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...                1\n",
      "1    우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...                2\n",
      "2    너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...                2\n",
      "3    이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...                4\n",
      "4    아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...                3\n",
      "..                                                 ...              ...\n",
      "495  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...                2\n",
      "496  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...                2\n",
      "497  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...                1\n",
      "498  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...                2\n",
      "499  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....                0\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 예측된 결과 출력\n",
    "print(test_data[['text', 'predicted_class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "227705a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>t_495</td>\n",
       "      <td>미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>t_496</td>\n",
       "      <td>교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>t_497</td>\n",
       "      <td>야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>t_498</td>\n",
       "      <td>야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>t_499</td>\n",
       "      <td>엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx                                               text  predicted_class\n",
       "0    t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...                1\n",
       "1    t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...                2\n",
       "2    t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...                2\n",
       "3    t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...                4\n",
       "4    t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...                3\n",
       "..     ...                                                ...              ...\n",
       "495  t_495  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...                2\n",
       "496  t_496  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...                2\n",
       "497  t_497  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...                1\n",
       "498  t_498  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...                2\n",
       "499  t_499  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....                0\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f231b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 저장\n",
    "test_data[['idx', 'predicted_class']].to_csv(\"submission_kcvert.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
