{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d939b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a13347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path =\"~/aiffel/dktc/advanced_general_conversation_test_A.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "# test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5558c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['협박 대화', '기타 괴롭힘 대화', '갈취 대화', '직장 내 괴롭힘 대화', '일반 대화'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db99d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'협박 대화' : 0, '갈취 대화' : 1, '직장 내 괴롭힘 대화' :2, '기타 괴롭힘 대화' : 3, '일반 대화' : 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8065c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['int_class'] = train_data['class'].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f6aa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>int_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>4520</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>그 사람 또 늦게 왔어요.\\n진짜? 지난번에도 지각하더니.\\n아니, 무슨 일하는 태...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>4521</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>네 친구 또 돈 빌려 달라고 했어.\\n진짜? 지난번에도 안 갚았잖아.\\n아니, 무슨...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>4522</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>그 동료 또 실수했어요.\\n진짜? 이번엔 또 뭐야?\\n아니, 기본적인 것도 못 하는...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>4523</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>걔 또 허세 부리더라.\\n진짜? 저번에도 그러지 않았어?\\n아니, 대체 왜 저러는 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>4524</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>그 사람 또 자기합리화했어요.\\n진짜? 매번 그러더니.\\n아니, 실수를 인정하는 게...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4525 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx      class                                       conversation  \\\n",
       "0        0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
       "1        1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
       "2        2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
       "3        3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
       "4        4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
       "...    ...        ...                                                ...   \n",
       "4520  4520  기타 괴롭힘 대화  그 사람 또 늦게 왔어요.\\n진짜? 지난번에도 지각하더니.\\n아니, 무슨 일하는 태...   \n",
       "4521  4521  기타 괴롭힘 대화  네 친구 또 돈 빌려 달라고 했어.\\n진짜? 지난번에도 안 갚았잖아.\\n아니, 무슨...   \n",
       "4522  4522  기타 괴롭힘 대화  그 동료 또 실수했어요.\\n진짜? 이번엔 또 뭐야?\\n아니, 기본적인 것도 못 하는...   \n",
       "4523  4523  기타 괴롭힘 대화  걔 또 허세 부리더라.\\n진짜? 저번에도 그러지 않았어?\\n아니, 대체 왜 저러는 ...   \n",
       "4524  4524  기타 괴롭힘 대화  그 사람 또 자기합리화했어요.\\n진짜? 매번 그러더니.\\n아니, 실수를 인정하는 게...   \n",
       "\n",
       "      int_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             3  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "4520          3  \n",
       "4521          3  \n",
       "4522          3  \n",
       "4523          3  \n",
       "4524          3  \n",
       "\n",
       "[4525 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea880c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af6d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.8.attention.self.value.weight', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.embeddings.position_ids', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.query.weight', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFBertModel.from_pretrained(MODEL_NAME, num_labels=5, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580e462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장에서 가장 긴 토큰 개수: 374\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 토큰화 (문장별 토큰 개수 확인)\n",
    "tokenized_texts = [tokenizer.tokenize(text) for text in train_data['conversation']]\n",
    "\n",
    "# 각 문장의 토큰 개수 계산\n",
    "token_lengths = [len(tokens) for tokens in tokenized_texts]\n",
    "\n",
    "# 최대 토큰 개수 찾기\n",
    "max_token_length = max(token_lengths)\n",
    "\n",
    "print(f\"문장에서 가장 긴 토큰 개수: {max_token_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b655ce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54343"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전 개수 확인\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e775569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "# 특수 토큰 확인\n",
    "print(tokenizer.cls_token)\n",
    "print(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba626ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 토큰 인텍스, 문장, 토큰 수 확인\n",
    "max_token_idx = token_lengths.index(max(token_lengths))  # 가장 긴 문장의 인덱스\n",
    "max_token_text = train_data['conversation'].iloc[max_token_idx]  # 해당 문장\n",
    "max_token_count = token_lengths[max_token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "847be94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이게 어떻게 된거야.? 엄마 수술은 어떻게 된거냐고\\n 엄마가 이제 괜찮다고 해서 딱 봐도 많이 좋아지셨잖아. 굳이 수술까진 할 필요 없어보여서.\\n 뭐? 그걸 왜 누나가 정해? 누나가 의사야? 병원가서 정밀검사 받아보고 해야지. 큰 병이면 어쩌려고 그래?\\n 아 늙어서 몸도 성하지 않는 사람 수술해서 뭐 어쩔건데????\\n 그럼 내가 준 수술비는 어쨌는데. 급하다며 급하다고 해서 내가 돈 다 빼서 줬잖아. 그거 어딨냐고 !!!!!!!!!\\n 그건 다른 급한 곳에 썼어.\\n 하. 급한 곳? 뭔데 어디다 썼는데.\\n 엄마 모시고 살면 돈 나가는 곳이 한 두 군데니? 이것 저것 급한 곳들 돈 썼지. 니가 말하면 알아?\\n 이건 뭐야? 못 보던건데. 누나 또 명품샀어?\\n 아 내놔!!!!!!!! 니가 뭘 알아. 아니야 이거 원래 있던거야.\\n 하. 니가 그러고도 인간이야? 그게 어떤돈인데!!!!!!!!!!!! 내가 밤낮으로 잠도 못자가면서 번 돈 !!!!!! 엄마 수술비하라고 다 빼서 준 걸 니가 가방을 쳐 사는데 써???????????\\n 아 시끄러워. 나 바빠 가야해.\\n 이성을 잃은 듯 너같은 년이 죽어야하는데. 너같은 년은 살 가치가 없다. 너가 죽어 너가 !!!!!!!!!!!\\n 왜.왜이래??! 미쳤어?\\n 이제 도저히 못참겠다. 몇 년 동안 이게 몇 번째야? 이 짓거리 못하도록 그냥 널 병신 만드는게 낫겠다. 팔 다리를 부러뜨려야 밖으로 안싸돌아 다니지? 발목을 아주 잘라버려야겠어. 주변에 흉기를 찾는다\\n 미.미쳤어 왜이렇게 흥분해?!?!?\\n 공구함에 있던 망치를 들며 너 내가 오늘 가만 안둬. 미친 건 너야. 팔다리를 없애버리겠어.\\n 꺄아아아'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7446725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06fb3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max_token_count + 2 # 문장 최대 토큰 길이\n",
    "NUM_LABELS = 5  # 분류할 클래스 개수\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b4711a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 토큰화하는 함수\n",
    "def tokenize_texts(texts, labels):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),  # 리스트 형태로 변환\n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=MAX_LEN, \n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings[\"input_ids\"], encodings[\"attention_mask\"], tf.convert_to_tensor(labels, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff9c8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (8:2 비율로 train/val 나누기)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_data['conversation'], train_data['int_class'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f84d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 토큰화\n",
    "train_input_ids, train_attention_mask, train_labels = tokenize_texts(train_texts, train_labels)\n",
    "val_input_ids, val_attention_mask, val_labels = tokenize_texts(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5a5f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Dataset 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": train_input_ids, \"attention_mask\": train_attention_mask}, train_labels)\n",
    ").shuffle(len(train_texts)).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask}, val_labels)\n",
    ").batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dbd4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 (train_data['conversation'], train_data['int_class'] 사용)\n",
    "input_ids, attention_mask, label_tensor = tokenize_texts(train_data['conversation'], train_data['int_class'])\n",
    "\n",
    "# TensorFlow Dataset 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, label_tensor)\n",
    ")\n",
    "\n",
    "# 배치 및 섞기\n",
    "dataset = dataset.shuffle(len(train_data)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a83e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4525, 376), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "194956b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 376)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 376)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 127776768   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            645         dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 127,875,845\n",
      "Trainable params: 127,875,845\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# BERT 모델에 입력\n",
    "bert_output = model(input_ids, attention_mask=attention_mask)[1]\n",
    "x = Dropout(0.1)(bert_output)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output = Dense(NUM_LABELS, activation=\"softmax\")(x)  # 다중 클래스 분류\n",
    "\n",
    "# 모델 정의\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8302ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 설정 (patience=2)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # 검증 데이터 손실 기준\n",
    "    patience=2,  # 2 epoch 동안 개선되지 않으면 종료\n",
    "    restore_best_weights=True  # 가장 성능이 좋았던 가중치 복원\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195f4f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 347s 734ms/step - loss: 1.5969 - accuracy: 0.2412 - val_loss: 1.4266 - val_accuracy: 0.3249\n",
      "Epoch 2/10\n",
      "453/453 [==============================] - 330s 728ms/step - loss: 1.3021 - accuracy: 0.3613 - val_loss: 1.1438 - val_accuracy: 0.4696\n",
      "Epoch 3/10\n",
      "453/453 [==============================] - 330s 728ms/step - loss: 0.8870 - accuracy: 0.6282 - val_loss: 0.7632 - val_accuracy: 0.6807\n",
      "Epoch 4/10\n",
      "453/453 [==============================] - 330s 728ms/step - loss: 0.4986 - accuracy: 0.8157 - val_loss: 0.5901 - val_accuracy: 0.8033\n",
      "Epoch 5/10\n",
      "453/453 [==============================] - 330s 728ms/step - loss: 0.2902 - accuracy: 0.8994 - val_loss: 0.4763 - val_accuracy: 0.8508\n",
      "Epoch 6/10\n",
      "453/453 [==============================] - 330s 728ms/step - loss: 0.1544 - accuracy: 0.9533 - val_loss: 0.5254 - val_accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "453/453 [==============================] - 330s 728ms/step - loss: 0.1282 - accuracy: 0.9630 - val_loss: 0.7058 - val_accuracy: 0.8199\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]  # 조기 종료 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb9bdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60d26d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 F1-score: 0.8504\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 예측\n",
    "val_predictions = model.predict({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask})\n",
    "predicted_classes = np.argmax(val_predictions, axis=1)  # 확률값을 가장 높은 클래스 인덱스로 변환\n",
    "\n",
    "# F1-score 계산\n",
    "f1 = f1_score(val_labels, predicted_classes, average=\"weighted\")\n",
    "\n",
    "print(f\"검증 데이터 F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb8fb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_test_texts(texts):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings[\"input_ids\"], encodings[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "524b1c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003</th>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
       "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
       "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
       "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
       "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "test_json_path = os.getenv('HOME')+'/aiffel/dktc/data/test.json'\n",
    "\n",
    "# JSON 파일 불러오기\n",
    "with open(test_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 변환: key를 인덱스로 하고, 내부 \"text\" 값을 컬럼으로 변환\n",
    "test_data = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf40d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_mask = tokenize_test_texts(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da6a61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 수행\n",
    "predictions = model.predict({\"input_ids\": test_input_ids, \"attention_mask\": test_attention_mask})\n",
    "\n",
    "# 확률값을 가장 높은 클래스 인덱스로 변환\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 결과를 데이터프레임에 추가\n",
    "test_data['target'] = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57464a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  target\n",
      "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...       1\n",
      "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...       2\n",
      "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...       2\n",
      "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...       3\n",
      "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...       2\n",
      "...                                                  ...     ...\n",
      "t_495  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...       2\n",
      "t_496  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...       2\n",
      "t_497  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...       1\n",
      "t_498  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...       2\n",
      "t_499  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....       1\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 예측된 결과 출력\n",
    "print(test_data[['text', 'target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c508896d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_000</th>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_001</th>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_002</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_003</th>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_004</th>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...       1\n",
       "t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...       2\n",
       "t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...       2\n",
       "t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...       3\n",
       "t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...       2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c433c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    145\n",
       "3    143\n",
       "1    107\n",
       "0     99\n",
       "4      6\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a2fc505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  target\n",
       "0  t_000       1\n",
       "1  t_001       2\n",
       "2  t_002       2\n",
       "3  t_003       3\n",
       "4  t_004       2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = test_data[['target']].reset_index()\n",
    "output_df.rename(columns={'index': 'idx'}, inplace=True)\n",
    "\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27e61db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getenv('HOME')+'/aiffel/dktc/submission_kcelectra.csv'\n",
    "output_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
